# -*- coding: utf-8 -*-
#
# Copyright (C) 2019 Max-Planck-Gesellschaft zur FÃ¶rderung der Wissenschaften e.V. (MPG),
# acting on behalf of its Max Planck Institute for Intelligent Systems and the
# Max Planck Institute for Biological Cybernetics. All rights reserved.
#
# Max-Planck-Gesellschaft zur FÃ¶rderung der Wissenschaften e.V. (MPG) is holder of all proprietary rights
# on this computer program. You can only use this computer program if you have closed a license agreement
# with MPG or you get the right to use the computer program from someone who is authorized to grant you that right.
# Any use of the computer program without a valid license is prohibited and liable to prosecution.
# Contact: ps-license@tuebingen.mpg.de
#
#
# If you use this code in a research publication please consider citing the following:
#
# Expressive Body Capture: 3D Hands, Face, and Body from a Single Image <https://arxiv.org/abs/1904.05866>
#
#
# Code Developed by:
# Nima Ghorbani <https://nghorbani.github.io/>
#
# 2018.12.13

import numpy as np

import torch
import torch.nn as nn

# from smplx.lbs import lbs
from human_body_prior.body_model.lbs import lbs
import sys


class BodyModel(nn.Module):

    def __init__(
            self,
            # SMPL parameters
            smpl_file_path,
            # DMPL parameters (optional)
            dmpl_file_path=None,
            num_betas=10,
            num_dmpls=None,
            num_expressions=80,
            use_posedirs=True,
            dtype=torch.float32,
            persistant_buffer=False
    ):
        '''
        åˆå§‹åŒ–æ–¹æ³•è´Ÿè´£åŠ è½½æ¨¡å‹å‚æ•°å¹¶è®¾ç½®åˆå§‹çŠ¶æ€ï¼š
        - æ¨¡å‹æ–‡ä»¶åŠ è½½ï¼šä»NPZæ–‡ä»¶åŠ è½½SMPLæ¨¡å‹å‚æ•°
        - æ¨¡å‹ç±»å‹è¯†åˆ«ï¼šæ ¹æ®å…³èŠ‚æ•°é‡è‡ªåŠ¨è¯†åˆ«æ¨¡å‹ç±»å‹ï¼ˆSMPL:69, SMPL-H:153, SMPL-X:162ç­‰ï¼‰
        - å‚æ•°åˆå§‹åŒ–ï¼šæ³¨å†Œå„ç§æ¨¡å‹å‚æ•°ä¸ºPyTorchç¼“å†²åŒºï¼ˆbufferï¼‰
        - ç»„ä»¶æ³¨å†Œï¼šä½¿ç”¨comp_registeræ–¹æ³•å°†å‚æ•°æ³¨å†Œä¸ºæ¨¡å‹çš„æŒä¹…åŒ–ç¼“å†²åŒº

        :param smpl_file_path: path to a SMPL model as pkl file
        :param num_betas: number of shape parameters to include.
        :param device: default on gpu
        :param dtype: float precision of the computations
        :return: verts, trans, pose, betas
        '''

        super(BodyModel, self).__init__()

        self.dtype = dtype

        # -- Load SMPL params --
        if '.npz' in smpl_file_path:
            smpl_dict = np.load(smpl_file_path, encoding='latin1')
        else:
            raise ValueError('smpl_file_path should be either a .pkl nor .npz file')

        # these are supposed for later convenient look up
        self.num_betas = num_betas
        self.num_dmpls = num_dmpls
        self.num_expressions = num_expressions

        njoints = smpl_dict['posedirs'].shape[2] // 3
        self.model_type = {69: 'smpl',
                           153: 'smplh',
                           162: 'smplx',
                           45: 'mano',
                           105: 'animal_horse',
                           102: 'animal_dog', }[njoints]

        assert self.model_type in ['smpl',
                                   'smplh',
                                   'smplx',
                                   'mano',
                                   'mano',
                                   'animal_horse',
                                   'animal_dog'], ValueError(
            'model_type should be in smpl/smplh/smplx/mano.')

        self.use_dmpl = False
        if num_dmpls is not None:
            if dmpl_file_path is not None:
                self.use_dmpl = True
            else:
                raise (ValueError('dmpl_file_path should be provided when using dmpls!'))

        if self.use_dmpl and self.model_type in ['smplx', 'mano', 'animal_horse', 'animal_dog']:
            raise (NotImplementedError('DMPLs only work with SMPL/SMPLH models for now.'))

        # Mean template vertices
        self.comp_register('init_v_template', torch.tensor(smpl_dict['v_template'][None], dtype=dtype), persistent=persistant_buffer)

        self.comp_register('f', torch.tensor(smpl_dict['f'].astype(np.int32), dtype=torch.int32), persistent=persistant_buffer)

        num_total_betas = smpl_dict['shapedirs'].shape[-1]

        if num_betas < 1:
            num_betas = num_total_betas
        else:
            pass

        shapedirs = smpl_dict['shapedirs'][:, :, :num_betas]
        self.comp_register('shapedirs', torch.tensor(shapedirs, dtype=dtype), persistent=persistant_buffer)

        if self.model_type == 'smplx':
            if smpl_dict['shapedirs'].shape[-1] > 300:
                begin_shape_id = 300
            else:
                begin_shape_id = 10
                num_expressions = smpl_dict['shapedirs'].shape[-1] - 10

            exprdirs = smpl_dict['shapedirs'][:, :, begin_shape_id:(begin_shape_id + num_expressions)]
            self.comp_register('exprdirs', torch.tensor(exprdirs, dtype=dtype), persistent=persistant_buffer)

            expression = torch.tensor(np.zeros((1, num_expressions)), dtype=dtype)
            self.comp_register('init_expression', expression, persistent=persistant_buffer)
        else:
            pass

        if self.use_dmpl:
            dmpldirs = np.load(dmpl_file_path)['eigvec']

            dmpldirs = dmpldirs[:, :, :num_dmpls]
            self.comp_register('dmpldirs', torch.tensor(dmpldirs, dtype=dtype), persistent=persistant_buffer)
        else:
            pass

        # Regressor for joint locations given shape - 6890 x 24
        self.comp_register('J_regressor', torch.tensor(smpl_dict['J_regressor'], dtype=dtype), persistent=persistant_buffer)

        # Pose blend shape basis: 6890 x 3 x 207, reshaped to 6890*30 x 207
        if use_posedirs:
            posedirs = smpl_dict['posedirs']
            posedirs = posedirs.reshape([posedirs.shape[0] * 3, -1]).T
            self.comp_register('posedirs', torch.tensor(posedirs, dtype=dtype), persistent=persistant_buffer)
        else:
            self.posedirs = None

        # indices of parents for each joints
        kintree_table = smpl_dict['kintree_table'].astype(np.int32)
        self.comp_register('kintree_table', torch.tensor(kintree_table, dtype=torch.int32), persistent=persistant_buffer)

        # LBS weights
        # weights = np.repeat(smpl_dict['weights'][np.newaxis], batch_size, axis=0)
        weights = smpl_dict['weights']
        self.comp_register('weights', torch.tensor(weights, dtype=dtype), persistent=persistant_buffer)

        self.comp_register('init_trans', torch.zeros((1, 3), dtype=dtype), persistent=persistant_buffer)
        # self.register_parameter('trans', nn.Parameter(trans, requires_grad=True))

        # root_orient
        # if self.model_type in ['smpl', 'smplh']:
        self.comp_register('init_root_orient', torch.zeros((1, 3), dtype=dtype), persistent=persistant_buffer)

        # pose_body
        if self.model_type in ['smpl', 'smplh', 'smplx']:
            self.comp_register('init_pose_body', torch.zeros((1, 63), dtype=dtype), persistent=persistant_buffer)
        elif self.model_type == 'animal_horse':
            self.comp_register('init_pose_body', torch.zeros((1, 105), dtype=dtype), persistent=persistant_buffer)
        elif self.model_type == 'animal_dog':
            self.comp_register('init_pose_body', torch.zeros((1, 102), dtype=dtype), persistent=persistant_buffer)
        else:
            pass

        # pose_hand
        if self.model_type in ['smpl']:
            self.comp_register('init_pose_hand', torch.zeros((1, 1 * 3 * 2), dtype=dtype), persistent=persistant_buffer)
        elif self.model_type in ['smplh', 'smplx']:
            self.comp_register('init_pose_hand', torch.zeros((1, 15 * 3 * 2), dtype=dtype), persistent=persistant_buffer)
        elif self.model_type in ['mano']:
            self.comp_register('init_pose_hand', torch.zeros((1, 15 * 3), dtype=dtype), persistent=persistant_buffer)
        else:
            pass

        # face poses
        if self.model_type == 'smplx':
            self.comp_register('init_pose_jaw', torch.zeros((1, 1 * 3), dtype=dtype), persistent=persistant_buffer)
            self.comp_register('init_pose_eye', torch.zeros((1, 2 * 3), dtype=dtype), persistent=persistant_buffer)
        else:
            pass

        self.comp_register('init_betas', torch.zeros((1, num_betas), dtype=dtype), persistent=persistant_buffer)

        if self.use_dmpl:
            self.comp_register('init_dmpls', torch.zeros((1, num_dmpls), dtype=dtype), persistent=persistant_buffer)

    def comp_register(self, name, value, persistent=False):
        if sys.version_info[0] > 2:
            self.register_buffer(name, value, persistent)
        else:
            self.register_buffer(name, value)

    def r(self):
        from human_body_prior.tools.omni_tools import copy2cpu as c2c
        return c2c(self.forward().v)

    def forward(self,
                root_orient=None,
                pose_body=None,
                pose_hand=None,
                pose_jaw=None,
                pose_eye=None,
                betas=None,
                trans=None,
                dmpls=None,
                expression=None,
                v_template=None,
                joints=None,
                v_shaped=None,
                return_dict=False,
                **kwargs):
        '''
        å‰å‘ä¼ æ’­æ–¹æ³•æ¥æ”¶å„ç§äººä½“å‚æ•°å¹¶è®¡ç®—æœ€ç»ˆçš„ç½‘æ ¼é¡¶ç‚¹ï¼š
        - å‚æ•°å¤„ç†ï¼šå¤„ç†å„ç§å¯é€‰å‚æ•°ï¼Œè®¾ç½®é»˜è®¤å€¼
        - å§¿åŠ¿ç»„åˆï¼šå°†å„éƒ¨ä½å§¿åŠ¿ç»„åˆæˆå®Œæ•´å§¿åŠ¿å‘é‡
        - å½¢çŠ¶ç»„åˆï¼šç»„åˆbetaå½¢çŠ¶å‚æ•°å’ŒDMPL/è¡¨æƒ…å‚æ•°
        - LBSè®¡ç®—ï¼šè°ƒç”¨çº¿æ€§æ··åˆè’™çš®(LBS)è®¡ç®—æœ€ç»ˆé¡¶ç‚¹ä½ç½®
        - ç»“æœè¿”å›ï¼šè¿”å›é¡¶ç‚¹ã€é¢ã€å…³èŠ‚ä½ç½®ç­‰ä¿¡æ¯

        :param root_orient: æ ¹å…³èŠ‚æœå‘
        :param pose_body: èº«ä½“å§¿æ€
        :param pose_hand: æ‰‹éƒ¨å§¿æ€
        :param pose_jaw: ä¸‹é¢Œå§¿æ€
        :param pose_eye: çœ¼ç›å§¿æ€
        :param betas: å½¢çŠ¶å‚æ•°, æ§åˆ¶äººä½“çš„æ•´ä½“å½¢çŠ¶ç‰¹å¾
        :param expression: è¡¨æƒ…å‚æ•°, ä»…é€‚ç”¨äºSMPL-Xæ¨¡å‹ï¼Œæ§åˆ¶é¢éƒ¨è¡¨æƒ…å˜åŒ–
        :param dmpls: åŠ¨æ€å½¢çŠ¶å‚æ•°, ä»…é€‚ç”¨äºSMPL/SMPL-Hæ¨¡å‹ï¼Œæ•æ‰æ›´ç»†å¾®çš„å½¢çŠ¶å˜åŒ–
        :param trans: å¹³ç§»å‚æ•°, æ§åˆ¶äººä½“åœ¨3Dç©ºé—´ä¸­çš„ä½ç½®
        :param v_template: æ¨¡æ¿ç½‘æ ¼é¡¶ç‚¹, å¯é€‰å‚æ•°ï¼Œå…è®¸ç”¨æˆ·æä¾›è‡ªå®šä¹‰çš„æ¨¡æ¿ç½‘æ ¼
        :param joints: å…³èŠ‚ä½ç½®, å¯é€‰å‚æ•°ï¼Œå…è®¸ç”¨æˆ·æä¾›è‡ªå®šä¹‰çš„å…³èŠ‚ä½ç½®
        :param v_shaped: å˜å½¢åçš„ç½‘æ ¼é¡¶ç‚¹, å¯é€‰å‚æ•°ï¼Œå…è®¸ç”¨æˆ·æä¾›é¢„å˜å½¢çš„ç½‘æ ¼é¡¶ç‚¹
        :param return_dict: æ˜¯å¦ä»¥å­—å…¸å½¢å¼è¿”å›ç»“æœ
        :param kwargs: å…¶ä»–å¯é€‰å‚æ•°

        :return: åŒ…å«é¡¶ç‚¹ã€é¢ã€å…³èŠ‚ä½ç½®ç­‰ä¿¡æ¯çš„å­—å…¸æˆ–å¯¹è±¡
        '''
        batch_size = 1

        # compute batchsize by any of the provided variables
        for arg in [root_orient, pose_body, pose_hand, pose_jaw, pose_eye, betas, trans, dmpls, expression, v_template, joints]:
            if arg is not None:
                batch_size = arg.shape[0]
                break

        # assert not (v_template is not None and betas is not None), ValueError('vtemplate and betas could not be used jointly.')
        assert self.model_type in ['smpl', 'smplh', 'smplx', 'mano', 'animal_horse', 'animal_dog'], ValueError(
            'model_type should be in smpl/smplh/smplx/mano')
        if root_orient is None:  root_orient = self.init_root_orient.expand(batch_size, -1)

        if self.model_type in ['smplh', 'smpl']:
            if pose_body is None:  pose_body = self.init_pose_body.expand(batch_size, -1)
            if pose_hand is None:  pose_hand = self.init_pose_hand.expand(batch_size, -1)
        elif self.model_type == 'smplx':
            if pose_body is None:  pose_body = self.init_pose_body.expand(batch_size, -1)
            if pose_hand is None:  pose_hand = self.init_pose_hand.expand(batch_size, -1)
            if pose_jaw is None:  pose_jaw = self.init_pose_jaw.expand(batch_size, -1)
            if pose_eye is None:  pose_eye = self.init_pose_eye.expand(batch_size, -1)
        elif self.model_type in ['mano', ]:
            if pose_hand is None:  pose_hand = self.init_pose_hand.expand(batch_size, -1)
        elif self.model_type in ['animal_horse', 'animal_dog']:
            if pose_body is None:  pose_body = self.init_pose_body.expand(batch_size, -1)
        else:
            pass

        if pose_hand is None and self.model_type not in ['animal_horse', 'animal_dog']:
            pose_hand = self.init_pose_hand.expand(batch_size, -1)

        if trans is None: trans = self.init_trans.expand(batch_size, -1)
        if v_template is None: v_template = self.init_v_template.expand(batch_size, -1, -1)
        if betas is None: betas = self.init_betas.expand(batch_size, -1)

        full_pose = None
        if self.model_type in ['smplh', 'smpl']:
            full_pose = torch.cat([root_orient, pose_body, pose_hand], dim=-1)
        elif self.model_type == 'smplx':
            # orient:3, body:63, jaw:3, eyel:3, eyer:3, handl, handr
            full_pose = torch.cat([root_orient, pose_body, pose_jaw, pose_eye, pose_hand], dim=-1)
        elif self.model_type in ['mano', ]:
            full_pose = torch.cat([root_orient, pose_hand], dim=-1)
        elif self.model_type in ['animal_horse', 'animal_dog']:
            full_pose = torch.cat([root_orient, pose_body], dim=-1)
        else:
            pass

        if self.use_dmpl:
            if dmpls is None: dmpls = self.init_dmpls.expand(batch_size, -1)
            shape_components = torch.cat([betas, dmpls], dim=-1)
            shapedirs = torch.cat([self.shapedirs, self.dmpldirs], dim=-1)
        elif self.model_type == 'smplx':
            if expression is None: expression = self.init_expression.expand(batch_size, -1)
            shape_components = torch.cat([betas, expression], dim=-1)
            shapedirs = torch.cat([self.shapedirs, self.exprdirs], dim=-1)
        else:
            shape_components = betas
            shapedirs = self.shapedirs

        """
        LBS æ˜¯ä»€ä¹ˆï¼Ÿ
        - çº¿æ€§æ··åˆè’™çš®ï¼ˆLinear Blend Skinningï¼‰ï¼Œä¹Ÿç§°ä¸ºéª¨éª¼åŠ¨ç”»ï¼ˆSkeletal Animationï¼‰ æˆ–åˆšä½“è’™çš®ï¼ˆRigid Skinningï¼‰ï¼Œ
            æ˜¯è®¡ç®—æœºå›¾å½¢å­¦å’Œè®¡ç®—æœºåŠ¨ç”»ä¸­æœ€æ ¸å¿ƒã€æœ€å¹¿æ³›åº”ç”¨çš„æŠ€æœ¯ä¹‹ä¸€ã€‚å®ƒç”¨äºé©±åŠ¨è§’è‰²ï¼ˆæ— è®ºæ˜¯äººã€åŠ¨ç‰©è¿˜æ˜¯æ€ªç‰©ï¼‰çš„å˜å½¢å’Œè¿åŠ¨ã€‚
            
        éª¨éª¼ï¼ˆSkeletonï¼‰ï¼š
        - è¿™æ˜¯ä¸€ä¸ªç”±å…³èŠ‚ï¼ˆJointsï¼‰ å’Œéª¨éª¼ï¼ˆBonesï¼‰ ç»„æˆçš„å±‚æ¬¡åŒ–ç»“æ„ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªæ ‘å½¢ç»“æ„ï¼Œç§°ä¸ºâ€œ kinematics tree â€æˆ–â€œ kintree â€ï¼‰ã€‚
        - æ¯ä¸ªå…³èŠ‚çš„å˜æ¢ï¼ˆæ—‹è½¬ã€å¹³ç§»ï¼‰ä¼šå½±å“åˆ°å…¶æ‰€æœ‰å­å…³èŠ‚å’Œå­éª¨éª¼ã€‚ä¾‹å¦‚ï¼Œè½¬åŠ¨è‚©è†€ï¼Œæ•´ä¸ªæ‰‹è‡‚ï¼ˆè‚˜éƒ¨ã€æ‰‹è…•ã€æ‰‹ï¼‰éƒ½ä¼šè·Ÿç€åŠ¨ã€‚
        - åœ¨SMPLæ¨¡å‹ä¸­ï¼Œè¿™å¯¹åº”ç€ kintree_tableã€‚

        è’™çš®ç½‘æ ¼ï¼ˆSkinned Meshï¼‰ï¼š
        - è¿™æ˜¯ç”¨æˆ·æœ€ç»ˆçœ‹åˆ°çš„3Dæ¨¡å‹è¡¨é¢ï¼Œç”±é¡¶ç‚¹ï¼ˆVerticesï¼‰å’Œé¢ï¼ˆFacesï¼‰æ„æˆã€‚
        - åœ¨LBSä¸­ï¼Œç½‘æ ¼é¡¶ç‚¹ä¸ç›´æ¥å®šä¹‰è‡ªå·±çš„ä½ç½®ï¼Œè€Œæ˜¯é€šè¿‡éª¨éª¼æ¥é©±åŠ¨ã€‚

        è’™çš®æƒé‡ï¼ˆSkinning Weightsï¼‰ï¼š
        - è¿™æ˜¯LBSçš„â€œé­”æ³•â€æ‰€åœ¨ã€‚æ¯ä¸ªé¡¶ç‚¹éƒ½å…³è”åˆ°ä¸€æ ¹æˆ–å¤šæ ¹éª¨éª¼ï¼Œå¹¶æ‹¥æœ‰ä¸€ä¸ªå¯¹åº”çš„æƒé‡ï¼ˆWeightï¼‰ï¼Œè¡¨ç¤ºè¯¥éª¨éª¼å¯¹é¡¶ç‚¹å½±å“åŠ›çš„å¤§å°ã€‚
        - æƒé‡é€šå¸¸åœ¨ [0, 1] èŒƒå›´å†…ï¼Œå¹¶ä¸”å¯¹äºä¸€ä¸ªé¡¶ç‚¹ï¼Œæ‰€æœ‰å½±å“å®ƒçš„éª¨éª¼çš„æƒé‡ä¹‹å’Œä¸º1ã€‚
        - ä¾‹å¦‚ï¼Œæ‰‹è…•å¤„çš„ä¸€ä¸ªé¡¶ç‚¹å¯èƒ½ä¸»è¦å—æ‰‹è…•å…³èŠ‚å½±å“ï¼ˆæƒé‡0.8ï¼‰ï¼Œä½†ä¹Ÿç¨å¾®å—å°è‡‚å…³èŠ‚å½±å“ï¼ˆæƒé‡0.2ï¼‰ï¼Œè¿™ä½¿å¾—åœ¨æ‰‹è…•å¼¯æ›²æ—¶ï¼Œå˜å½¢ä¼šæ›´åŠ å¹³æ»‘è‡ªç„¶ã€‚

        åœ¨SMPLæ¨¡å‹ä¸­ï¼Œè¿™å¯¹åº”ç€ weights çŸ©é˜µã€‚
        - ç»‘å®šå§¿åŠ¿ï¼ˆBind Poseï¼‰ / T-Poseï¼š
        - è¿™æ˜¯éª¨éª¼å’Œç½‘æ ¼çš„åˆå§‹å‚è€ƒå§¿åŠ¿ã€‚é€šå¸¸æ˜¯ä¸€ä¸ªæ˜“äºå»ºæ¨¡å’Œç»‘å®šçš„å§¿åŠ¿ï¼Œå¦‚è‘—åçš„â€œT-Poseâ€ã€‚
        - åœ¨è¿™ä¸ªå§¿åŠ¿ä¸‹ï¼Œæ¯ä¸ªå…³èŠ‚éƒ½æœ‰ä¸€ä¸ªé€†ç»‘å®šçŸ©é˜µï¼ˆInverse Bind Matrixï¼‰ï¼Œè®°ä¸º $G_{j}^{-1}$ã€‚è¿™ä¸ªçŸ©é˜µçš„ä½œç”¨æ˜¯ï¼šå°†é¡¶ç‚¹ä»ä¸–ç•Œåæ ‡å˜æ¢åˆ°å¯¹åº”å…³èŠ‚çš„å±€éƒ¨ç©ºé—´åæ ‡ã€‚
        
        æ¨¡æ¿ç½‘æ ¼ v_template
        
        Jtr æŒ‡çš„æ˜¯â€œç»è¿‡å§¿æ€ä¸å½¢çŠ¶å˜å½¢åçš„å…³èŠ‚åœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„ä¸‰ç»´ä½ç½®â€ã€‚æ›´å‡†ç¡®åœ°è¯´ï¼š
        Jtr = Transformed Jointsï¼ˆæˆ– Joint Transforms Result ä¸­çš„ joint positionsï¼‰
        
        vertsï¼š
        ğŸ‘‰ ç»è¿‡ shape + pose + LBS ä¹‹åçš„ æœ€ç»ˆç½‘æ ¼é¡¶ç‚¹ä½ç½® (B, V, 3)
        Jtrï¼š
        ğŸ‘‰ ç»è¿‡ shape + pose + forward kinematics ä¹‹åçš„ å…³èŠ‚ä½ç½® (B, J, 3)
        """
        verts, Jtr = lbs(
            betas=shape_components,
            pose=full_pose,
            v_template=v_template,
            shapedirs=shapedirs,
            posedirs=self.posedirs,
            J_regressor=self.J_regressor,
            parents=self.kintree_table[0].long(),
            lbs_weights=self.weights,
            joints=joints,
            v_shaped=v_shaped,
            dtype=self.dtype,
        )

        Jtr = Jtr + trans.unsqueeze(dim=1)
        verts = verts + trans.unsqueeze(dim=1)

        res = {}
        res['v'] = verts
        res['f'] = self.f
        res['Jtr'] = Jtr  # Todo: ik can be made with vposer
        # res['bStree_table'] = self.kintree_table

        # if self.model_type == 'smpl':
        #     res['pose_body'] = pose_body
        # elif self.model_type == 'smplh':
        #     res['pose_body'] = pose_body
        #     res['pose_hand'] = pose_hand
        # elif self.model_type == 'smplx':
        #     res['pose_body'] = pose_body
        #     res['pose_hand'] = pose_hand
        #     res['pose_jaw'] = pose_jaw
        #     res['pose_eye'] = pose_eye
        # elif self.model_type in ['mano', 'mano']:
        #     res['pose_hand'] = pose_hand
        res['full_pose'] = full_pose

        if not return_dict:
            class result_meta(object):
                pass

            res_class = result_meta()
            for k, v in res.items():
                res_class.__setattr__(k, v)
            res = res_class
        else:
            pass

        return res
